{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import pyforest\n",
    "import texthero as hero\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data\n",
    "data = pd.read_csv('../inputs/fake_job_postings.csv')\n",
    "target = data['fraudulent']\n",
    "data.drop(['job_id','salary_range','department','benefits'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing target values form dataset\n",
    "data.drop(['fraudulent'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling null values \n",
    "data['required_education'].fillna('Unspecified',inplace = True)\n",
    "data['employment_type'].fillna('no_info_about_employment',inplace = True)\n",
    "data['required_experience'].fillna('experience_not_asked',inplace = True)\n",
    "data['industry'].fillna('industry_not_given',inplace = True)\n",
    "data['function'].fillna('function_not_given',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing catogorical data\n",
    "cat_cols = ['employment_type','required_experience','required_education','industry','function']\n",
    "for c in cat_cols:\n",
    "    encoded = pd.get_dummies(data[c])\n",
    "    data = pd.concat([data,encoded],axis = 1 )\n",
    "cat_cols = ['employment_type','required_experience','required_education','industry','function','location','company_profile']\n",
    "data.drop(cat_cols,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing with text data\n",
    "description = data['title'] + ' ' + data['description']+ ' ' +  data['requirements']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_desc = description.pipe(hero.clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import stem\n",
    "from nltk import tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "w_tokenizer = tokenize.WhitespaceTokenizer()\n",
    "\n",
    "\n",
    "# Use English stemmer.\n",
    "stemmer = stem.SnowballStemmer(\"english\")\n",
    "\n",
    "def stemming(text):\n",
    "    '''\n",
    "    input  : text \n",
    "    output :  lemmazitzed text\n",
    "    '''\n",
    "    return ' '.join([stemmer.stem(word) for word in w_tokenizer.tokenize(text)])\n",
    "clean_desc = clean_desc.apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_long_texts(text):\n",
    "    words = [word for word in text.split() if len(word)<21]\n",
    "    return ' '.join(words)\n",
    "def remove_digits(text):\n",
    "    return re.sub(r'[\\d\\|]', '', text)\n",
    "\n",
    "clean_desc = clean_desc.apply(remove_long_texts)\n",
    "clean_desc = clean_desc.apply(remove_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer( min_df = 0.05)\n",
    "tfidf_features = tfidf.fit_transform(clean_desc) \n",
    "tfidf_vect_df = pd.DataFrame(tfidf_features.todense(), columns = tfidf.get_feature_names())\n",
    "data = pd.concat([data, tfidf_vect_df], axis = 1)\n",
    "data.drop(['title','description','requirements'],axis = 1 , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=0)\n",
    "X_resampled, y_resampled = sm.fit_resample(data.values, target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics,model_selection\n",
    "\n",
    "def score(df,model):\n",
    "    \n",
    "    for fold in range(0,5):\n",
    "        scores = []\n",
    "        df_train = df[df[\"kfold\"] != fold].reset_index(drop=True)\n",
    "        df_valid = df[df[\"kfold\"] == fold].reset_index(drop=True)\n",
    "        \n",
    "        x_train = df_train.drop(['kfold','fraudulent'],axis=1)\n",
    "        y_train = df_train.fraudulent.values\n",
    "        \n",
    "        \n",
    "        x_valid = df_valid.drop(['kfold','fraudulent'],axis=1).values\n",
    "        y_valid = df_valid.fraudulent.values\n",
    "        \n",
    "        model.fit(x_train,y_train)\n",
    "        y_pred = model.predict(x_valid)\n",
    "        \n",
    "        scores.append(metrics.roc_auc_score(y_valid,y_pred))\n",
    "        #print(metrics.confusion_matrix(y_valid,y_pred))\n",
    "\n",
    "    score = np.mean(scores)   \n",
    "    return score\n",
    "    \n",
    "def best_parameter(df):\n",
    "\n",
    "    X = df.drop(['kfold','fraudulent'],axis=1)\n",
    "    Y = df.fraudulent.values\n",
    "        \n",
    "    hyper = {'C':[0.001,0.01,10,100,1000],\n",
    "             'gamma':[0.001,0.01,10,100,1000],\n",
    "             'kernel':['linear']\n",
    "            }\n",
    "    \n",
    "    gd=model_selection.GridSearchCV(estimator=svm.SVC(),\n",
    "                                    scoring = 'roc_auc',\n",
    "                                    param_grid=hyper,\n",
    "                                    n_jobs=-1,\n",
    "                                    verbose=True)\n",
    "    \n",
    "    gd.fit(X,Y)\n",
    "    return gd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(df):\n",
    "     #create a k-fold column and initialise it with -1\n",
    "    df[\"kfold\"] = -1\n",
    "    \n",
    "    #intialise kfold class\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    #filling kfold columns\n",
    "    for f,(t_,v_) in enumerate(kf.split(X=df,y=df.fraudulent)):\n",
    "        df.loc[v_,'kfold'] = f\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X_resampled,columns=data.columns)\n",
    "df['fraudulent'] = y_resampled\n",
    "df = df.sample(frac=1).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.model_selection import train_test_split'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#split the data for train and test\n",
    "X = df.drop('fraudulent',axis=1)\n",
    "y = df.fraudulent\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X_train.copy()\n",
    "train_data['fraudulent'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidf, open('../inputs/tf_idf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_folds(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intial roc_auc Score is : 0.9844242112338889\n"
     ]
    }
   ],
   "source": [
    "#training our training dataset on the best hyperparameter \n",
    "model = svm.SVC()\n",
    "intial_score = score(df,model)\n",
    "print(f\"Intial roc_auc Score is : {intial_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27222, 684)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34, 434, 343]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[34,434]+[343]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x483 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.transform(['afbhadjgfhjadsgfjadhsgfdsga'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['telecommuting', 'has_company_logo', 'has_questions', 'Contract',\n",
       "       'Full-time', 'Other', 'Part-time', 'Temporary',\n",
       "       'no_info_about_employment', 'Associate',\n",
       "       ...\n",
       "       'within', 'without', 'word', 'work', 'world', 'would', 'write',\n",
       "       'written', 'year', 'fraudulent'],\n",
       "      dtype='object', length=684)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
